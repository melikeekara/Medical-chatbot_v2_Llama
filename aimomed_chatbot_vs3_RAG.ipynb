{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tT1QF0qaGJ7"
      },
      "source": [
        "Gerekli Kurulumlar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "qlW6PeKvYAAN"
      },
      "outputs": [],
      "source": [
        "!pip install transformers accelerate bitsandbytes peft --quiet streamlit\n",
        "!pip install python-dotenv\n",
        "!npm install -g localtunnel\n",
        "!pip install PyPDF2 faiss-cpu sentence-transformers langchain\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fB0s0rxV1UTn"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade langchain langchain-community faiss-cpu PyPDF2 sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MHxeBIktaYUF"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "\n",
        "import os\n",
        "import re\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import transformers\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, set_seed\n",
        "from datetime import datetime\n",
        "from peft import PeftModel\n",
        "import matplotlib.pyplot as plt\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.text_splitter import CharacterTextSplitter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRFs4Y39bAvA"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5rnj-r2bFGQ"
      },
      "outputs": [],
      "source": [
        "!ls /content/drive/MyDrive/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eUdduK3DYbrX"
      },
      "outputs": [],
      "source": [
        "# Hugging Face Token Giri≈üi (Eƒüer gereklirse)\n",
        "from huggingface_hub import login\n",
        "login(\"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\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gByzPaRXaS_W"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "import shelve\n",
        "import re\n",
        "from datetime import datetime\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# --- Eklenen RAG i√ßin k√ºt√ºphaneler ---\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "# Ortam deƒüi≈ükenlerini y√ºkle\n",
        "load_dotenv()\n",
        "\n",
        "# Logo\n",
        "HORIZONTAL_RED = \"/content/drive/MyDrive/aƒ±_med.png\"\n",
        "\n",
        "# Sayfa ba≈ülƒ±ƒüƒ±\n",
        "st.set_page_config(page_title=\"AIMO MED\", page_icon=\"ü©∫\")\n",
        "st.title(\"ü©∫ AIMO MED\")\n",
        "\n",
        "# Dil se√ßimi ve sidebar\n",
        "with st.sidebar:\n",
        "    st.image(HORIZONTAL_RED, use_container_width=True)\n",
        "    lang = st.selectbox(\"üåê Dil Se√ßimi / Language:\", [\"T√ºrk√ße\", \"English\"])\n",
        "    st.header(\"üìÅ Ge√ßmi≈ü Sohbetler\" if lang == \"T√ºrk√ße\" else \"üìÅ Chat History\")\n",
        "\n",
        "st.markdown(\n",
        "    \"Bu chatbot, T√ºrk√ße ve ƒ∞ngilizce tƒ±bbi sorularƒ±nƒ±za yardƒ±mcƒ± olmak i√ßin eƒüitildi. Sorularƒ±nƒ±zƒ± yazabilirsiniz.\"\n",
        "    if lang == \"T√ºrk√ße\"\n",
        "    else \"This chatbot is trained to assist with medical questions in both Turkish and English. You can ask your questions.\"\n",
        ")\n",
        "\n",
        "def create_new_chat_id():\n",
        "    return datetime.now().strftime(\"chat_%Y%m%d_%H%M%S\")\n",
        "\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "if \"chat_key\" not in st.session_state:\n",
        "    st.session_state.chat_key = create_new_chat_id()\n",
        "\n",
        "# Yeni: PDF i√ßeriƒüi ve FAISS indeksini saklamak i√ßin\n",
        "if \"pdf_text\" not in st.session_state:\n",
        "    st.session_state.pdf_text = None\n",
        "if \"faiss_index\" not in st.session_state:\n",
        "    st.session_state.faiss_index = None\n",
        "\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    model_name = \"OnurYantira/llama3-8b-turkish-english-medical-merged\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    tokenizer.padding_side = \"right\"\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        device_map=\"auto\",\n",
        "        torch_dtype=torch.float16\n",
        "    )\n",
        "    return tokenizer, model\n",
        "\n",
        "tokenizer, model = load_model()\n",
        "\n",
        "# RAG yardƒ±mcƒ± fonksiyonlarƒ±\n",
        "def extract_text_from_pdf(file):\n",
        "    reader = PdfReader(file)\n",
        "    return \"\\n\".join([page.extract_text() or \"\" for page in reader.pages])\n",
        "\n",
        "def create_faiss_index(text):\n",
        "    chunks = CharacterTextSplitter(separator=\"\\n\", chunk_size=500, chunk_overlap=100).split_text(text)\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    return FAISS.from_texts(chunks, embeddings)\n",
        "\n",
        "def list_all_chats():\n",
        "    with shelve.open(\"chat_history\") as db:\n",
        "        return list(db.keys())\n",
        "\n",
        "def load_specific_chat(chat_key):\n",
        "    with shelve.open(\"chat_history\") as db:\n",
        "        return db.get(chat_key, [])\n",
        "\n",
        "def save_specific_chat(chat_key, messages):\n",
        "    with shelve.open(\"chat_history\") as db:\n",
        "        db[chat_key] = messages\n",
        "\n",
        "def extract_keywords(text, num_words=3):\n",
        "    words = re.findall(r'\\b\\w+\\b', text)\n",
        "    return \" \".join(words[:num_words])\n",
        "\n",
        "def format_chat_title(chat_key, messages):\n",
        "    if messages and messages[0][\"role\"] == \"user\":\n",
        "        summary = extract_keywords(messages[0][\"content\"])\n",
        "        return summary.capitalize()\n",
        "    try:\n",
        "        dt = datetime.strptime(chat_key, \"chat_%Y%m%d_%H%M%S\")\n",
        "        return dt.strftime(\"%d %B %Y - %H:%M\")\n",
        "    except:\n",
        "        return chat_key\n",
        "\n",
        "# Sidebar sohbet listesi\n",
        "with st.sidebar:\n",
        "    all_chats = list_all_chats()\n",
        "    chat_titles = [format_chat_title(chat, load_specific_chat(chat)) for chat in all_chats]\n",
        "\n",
        "    cols = st.columns([1, 1])\n",
        "    if cols[0].button(\"‚ûï Yeni Sohbet\" if lang == \"T√ºrk√ße\" else \"‚ûï New Chat\"):\n",
        "        new_key = create_new_chat_id()\n",
        "        st.session_state.chat_key = new_key\n",
        "        st.session_state.messages = []\n",
        "        save_specific_chat(new_key, [])\n",
        "        st.session_state.pdf_text = None\n",
        "        st.session_state.faiss_index = None\n",
        "        st.rerun()\n",
        "\n",
        "    if cols[1].button(\"üóë Sohbeti Sil\" if lang == \"T√ºrk√ße\" else \"üóë Delete Chat\"):\n",
        "        with shelve.open(\"chat_history\") as db:\n",
        "            if st.session_state.chat_key in db:\n",
        "                del db[st.session_state.chat_key]\n",
        "        st.session_state.messages = []\n",
        "        st.session_state.pdf_text = None\n",
        "        st.session_state.faiss_index = None\n",
        "        st.rerun()\n",
        "\n",
        "    if chat_titles:\n",
        "        st.markdown(\"### Sohbeti se√ßin:\" if lang == \"T√ºrk√ße\" else \"### Select a chat:\")\n",
        "        for i, title in enumerate(chat_titles):\n",
        "            if st.button(title, key=f\"chat_{i}\"):\n",
        "                selected_index = i\n",
        "                chat_key = all_chats[selected_index]\n",
        "                st.session_state.chat_key = chat_key\n",
        "                st.session_state.messages = load_specific_chat(chat_key)\n",
        "                st.session_state.pdf_text = None\n",
        "                st.session_state.faiss_index = None\n",
        "                st.rerun()\n",
        "\n",
        "# Mesaj stili\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        ".chat-container { display: flex; margin: 10px 0; align-items: flex-start; }\n",
        ".chat-left { flex-direction: row; justify-content: flex-start; }\n",
        ".chat-right { flex-direction: row; justify-content: flex-end; }\n",
        "\n",
        ".avatar { font-size: 24px; margin: 0 10px; }\n",
        ".chat-bubble { max-width: 75%; padding: 12px 16px; border-radius: 16px; line-height: 1.6; word-wrap: break-word; border: 1px solid #ccc; }\n",
        "\n",
        ".user-msg { background-color: #e3f2fd; border-top-right-radius: 0; }\n",
        ".bot-msg { background-color: #f1f8e9; border-top-left-radius: 0; }\n",
        "\n",
        "@media (prefers-color-scheme: dark) {\n",
        "  .chat-bubble { color: #f9f9f9 !important; background-color: #333 !important; border: 1px solid #555 !important; }\n",
        "  .user-msg { background-color: #1565c0 !important; color: white !important; }\n",
        "  .bot-msg { background-color: #2e7d32 !important; color: white !important; }\n",
        "}\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Mesajlarƒ± g√∂ster\n",
        "for message in st.session_state.messages:\n",
        "    role = message[\"role\"]\n",
        "    content = message[\"content\"]\n",
        "    if role == \"user\":\n",
        "        st.markdown(f'''\n",
        "            <div class=\"chat-container chat-right\">\n",
        "                <div class=\"chat-bubble user-msg\">{content}</div>\n",
        "                <div class=\"avatar\">üë§</div>\n",
        "            </div>\n",
        "        ''', unsafe_allow_html=True)\n",
        "    else:\n",
        "        st.markdown(f'''\n",
        "            <div class=\"chat-container chat-left\">\n",
        "                <div class=\"avatar\">ü§ñ</div>\n",
        "                <div class=\"chat-bubble bot-msg\">{content}</div>\n",
        "            </div>\n",
        "        ''', unsafe_allow_html=True)\n",
        "\n",
        "# Girdi ve cevap √ºretimi (PDF destekli)\n",
        "prompt = st.chat_input(\"Bir ≈üey yazƒ±n ve/veya PDF y√ºkleyin...\", accept_file=True, file_type=[\"pdf\"])\n",
        "user_input = prompt.text if prompt else \"\"\n",
        "uploaded_file = prompt.files[0] if prompt and prompt.files else None\n",
        "\n",
        "# PDF y√ºklendiyse metni √ßƒ±kar ve FAISS olu≈ütur\n",
        "if uploaded_file:\n",
        "    pdf_text = extract_text_from_pdf(uploaded_file)\n",
        "    st.session_state.pdf_text = pdf_text\n",
        "    st.session_state.faiss_index = create_faiss_index(pdf_text)\n",
        "\n",
        "# Giri≈ü sonrasƒ± kullanƒ±cƒ± mesajƒ± ekrana yazƒ±lsƒ±n ve ardƒ±ndan sadece cevap √ºretim kƒ±smƒ± tetiklensin\n",
        "if user_input and not st.session_state.get(\"last_user_input_processed\"):\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "    save_specific_chat(st.session_state.chat_key, st.session_state.messages)\n",
        "    st.session_state.last_user_input = user_input\n",
        "    st.session_state.last_user_input_processed = True\n",
        "    st.rerun()\n",
        "\n",
        "# Giri≈ü varsa ve kullanƒ±cƒ± mesajƒ± zaten i≈ülendi, ≈üimdi cevap √ºret\n",
        "if st.session_state.get(\"last_user_input_processed\"):\n",
        "    user_input = st.session_state.get(\"last_user_input\", \"\")\n",
        "    context = \"\"\n",
        "    if st.session_state.faiss_index:\n",
        "        docs = st.session_state.faiss_index.similarity_search(user_input, k=3)\n",
        "        context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "\n",
        "    system_prompt = (\n",
        "        \"Sen T√ºrk√ße konu≈üan yardƒ±mcƒ± bir medikal asistansƒ±n. Kƒ±sa, doƒüru ve profesyonel yanƒ±tlar ver.\"\n",
        "        if lang == \"T√ºrk√ße\"\n",
        "        else \"You are a helpful medical assistant. Provide concise, accurate, and professional answers.\"\n",
        "    )\n",
        "\n",
        "    full_prompt = (\n",
        "        \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\"\n",
        "        + system_prompt\n",
        "        + (\"\\n\\nEk bilgiler: \" + context if context else \"\")\n",
        "        + \"<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\"\n",
        "        + user_input\n",
        "        + \"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\"\n",
        "    )\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    inputs = tokenizer(full_prompt, return_tensors=\"pt\").to(device)\n",
        "    model.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=512,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "            repetition_penalty=1.1\n",
        "        )\n",
        "\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
        "    response = generated_text.split(\"<|start_header_id|>assistant<|end_header_id|>\\n\")[-1].strip()\n",
        "    response = re.sub(rf\"{re.escape(user_input)}\", \"\", response).strip()\n",
        "    response = re.sub(r\"(<\\|.*?\\|>|system|user|assistant)\", \"\", response, flags=re.IGNORECASE).strip()\n",
        "\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "    save_specific_chat(st.session_state.chat_key, st.session_state.messages)\n",
        "    st.session_state.last_user_input_processed = False\n",
        "    st.session_state.last_user_input = \"\"\n",
        "    st.rerun()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsePX21_boX1"
      },
      "outputs": [],
      "source": [
        "!curl https://loca.lt/mytunnelpassword\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Tnw6kRBbrcF"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}